import pickle
import itertools
import datetime
import requests
import os
import warnings

import numpy as np
import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt

from pandas import datetime
from operator import itemgetter
from math import sqrt

from sklearn import preprocessing
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression, HuberRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

from xgboost import XGBRegressor
from catboost import CatBoostRegressor

import h2o
from h2o.automl import H2OAutoML

import keras
from keras.models import Sequential, load_model
from keras.layers.core import Dense, Dropout, Activation

from sklearn.preprocessing import MinMaxScaler

# Define the list of training files
train_files = ['/kaggle/input/kriti-stock-market-prediction/1_train.csv',
 '/kaggle/input/kriti-stock-market-prediction/2_train.csv',
'/kaggle/input/kriti-stock-market-prediction/3_train.csv',
'/kaggle/input/kriti-stock-market-prediction/4_train.csv']

# Create an empty dictionary to store the models and scalers
models = {}
scalers={}

for i, file in enumerate(train_files):
    train_data = pd.read_csv(file)
    print("Company-{}".format(i+1))
    dataplot = sb.heatmap(train_data.corr(), cmap="YlGnBu", annot=True)
    plt.show()
# Create an empty dictionary to store the models and scalers
models = {}
scalers={}
# Loop through each training file
for i, file in enumerate(train_files):

    # Define the features
    X_train = train_data[['Adj Close']]
    sc={}
    
    min_max_scaler = preprocessing.MinMaxScaler()
    X_train['Adj Close'] = min_max_scaler.fit_transform(X_train['Adj Close'].values.reshape(-1,1))
    sc['Adj Close']=min_max_scaler
    
    
    y_train = train_data['Close']
    min_max_scaler = preprocessing.MinMaxScaler()
    y_train = min_max_scaler.fit_transform(y_train.values.reshape(-1,1))
    sc['Close']=min_max_scaler
    
    

    # Create the linear regression model
    model = LinearRegression()

    # Fit the model to the training data
    model.fit(X_train, y_train)
    temp_preds = model.predict(X_train)
    temp_preds = sc['Close'].inverse_transform(np.array([temp_preds]).reshape(1,-1))
    X_train['close_preds'] = temp_preds[0]
    X_train['Close'] = train_data['Close']
    X_train['Adj Close'] = (sc['Adj Close'].inverse_transform(np.array([X_train['Adj Close']]).reshape(1,-1)))[0]

    # Store the model in the dictionary using the company ID as the key
    models[i+1] = model
    scalers[i+1]=sc
# Load the testing data
test_data = pd.read_csv('/kaggle/input/kriti-stock-market-prediction/test.csv')

#Create a dataframe for the submission
submission_df = pd.DataFrame(columns=['ID', 'Close'])
submission_df['ID'] = test_data['ID']

# Loop through each row of the testing data
for i, row in test_data.iterrows():
    # Get the company ID
    company_id = row['Company']
    
    # Get the corresponding model for the current company ID
    model = models[company_id]
    slr = scalers[company_id]

    # Make predictions on the current row of testing data
    X_test = row[['Adj Close']]
    X_test['Adj Close']= slr['Adj Close'].transform(np.array([X_test['Adj Close']]).reshape(1,-1))
    X_test = X_test[['Adj Close']].to_numpy().reshape(1, -1)
    row_id = row['ID']
    y_pred = model.predict(X_test)
    y_pred = slr['Close'].inverse_transform(np.array([y_pred]).reshape(1,-1))
    submission_df.loc[row_id, 'Close'] = y_pred[0]
submission_df.head()
submission_df.to_csv("submission_lr_AdjClose.csv", index=False)
